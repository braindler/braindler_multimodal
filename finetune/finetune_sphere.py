#!/usr/bin/env python3
"""
–§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –æ–¥–Ω–æ–π —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä—ã (047, 048, –∏–ª–∏ 049)

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LoRA –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–æ–±—É—á–∫–∏ –º–æ–¥–µ–ª–∏

¬© 2025 NativeMind - NativeMindNONC License
"""

import os
import sys
import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from datasets import load_dataset
from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training

def finetune_sphere(
    base_model_name,  # "nativemind/braindler_final_model" or "nativemind/mozgach_full_trained_model"
    dataset_path,
    sphere,  # "047", "048", "049"
    output_dir,
    epochs=3,
    batch_size=2,
    learning_rate=2e-4,
    use_8bit=False
):
    """
    –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ñ–µ—Ä—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LoRA
    
    Args:
        base_model_name: –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (Braindler –∏–ª–∏ Mozgach)
        dataset_path: –ü—É—Ç—å –∫ JSONL –¥–∞—Ç–∞—Å–µ—Ç—É
        sphere: –ù–æ–º–µ—Ä —Å—Ñ–µ—Ä—ã ("047", "048", "049")
        output_dir: –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        learning_rate: Learning rate
        use_8bit: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 8-bit –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
    """
    
    sphere_names = {
        "047": "–°–õ–ï–î–û–í–ê–¢–ï–õ–¨",
        "048": "–ü–†–û–ö–£–†–û–†",
        "049": "–°–£–î–¨–Ø"
    }
    
    print("="*80)
    print(f"‚öñÔ∏è  –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –°—Ñ–µ—Ä—ã {sphere}: {sphere_names[sphere]}")
    print("="*80)
    print()
    print(f"üì¶ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {base_model_name}")
    print(f"üìö –î–∞—Ç–∞—Å–µ—Ç: {dataset_path}")
    print(f"üíæ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
    print(f"üéØ –≠–ø–æ—Ö: {epochs}, Batch size: {batch_size}, LR: {learning_rate}")
    print()
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
    tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
        print("   ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω pad_token = eos_token")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
    
    model_kwargs = {
        "trust_remote_code": True,
        "device_map": "auto"
    }
    
    if use_8bit:
        model_kwargs["load_in_8bit"] = True
        print("   üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º 8-bit –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ")
    else:
        model_kwargs["torch_dtype"] = torch.float16
        print("   üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º FP16")
    
    model = AutoModelForCausalLM.from_pretrained(
        base_model_name,
        **model_kwargs
    )
    
    if use_8bit:
        model = prepare_model_for_kbit_training(model)
    
    print("   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model.num_parameters():,}")
    
    # 3. LoRA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    print("\nüîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA...")
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=16,  # Rank (–º–µ–Ω—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
        lora_alpha=32,
        lora_dropout=0.1,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # Attention layers
        bias="none"
    )
    
    model = get_peft_model(model, lora_config)
    
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    all_params = sum(p.numel() for p in model.parameters())
    
    print(f"   ‚úÖ LoRA –ø—Ä–∏–º–µ–Ω–µ–Ω")
    print(f"   –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,} ({100 * trainable_params / all_params:.2f}%)")
    print(f"   –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {all_params:,}")
    
    # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("\nüìö –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    dataset = load_dataset('json', data_files=dataset_path, split='train')
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å—Ñ–µ—Ä–µ
    role_map = {
        "047": "sphere_047_investigator",
        "048": "sphere_048_prosecutor",
        "049": "sphere_049_judge"
    }
    
    dataset = dataset.filter(lambda x: x['role'] == role_map[sphere])
    print(f"   üìä –ü—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –°—Ñ–µ—Ä—ã {sphere}: {len(dataset)}")
    
    if len(dataset) == 0:
        print("   ‚ùå –ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —ç—Ç–æ–π —Å—Ñ–µ—Ä—ã!")
        return None
    
    # 5. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    print("\nüî§ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    def format_instruction(example):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ Llama"""
        text = f"""<s>[INST] {example['instruction']}

{example['input']} [/INST]

{example['output']}</s>"""
        
        return tokenizer(
            text,
            truncation=True,
            max_length=2048,
            padding="max_length"
        )
    
    tokenized_dataset = dataset.map(
        format_instruction,
        remove_columns=dataset.column_names,
        desc="–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
    )
    
    print(f"   ‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(tokenized_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # 6. Training arguments
    print("\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
    
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=epochs,
        per_device_train_batch_size=batch_size,
        gradient_accumulation_steps=8,
        learning_rate=learning_rate,
        warmup_steps=100,
        logging_steps=10,
        save_steps=500,
        save_total_limit=3,
        fp16=not use_8bit,
        bf16=False,
        optim="adamw_torch",
        report_to=["tensorboard"],
        logging_dir=f"{output_dir}/logs",
        remove_unused_columns=False,
    )
    
    print("   ‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
    
    # 7. Data collator
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False
    )
    
    # 8. Trainer
    print("\nüèóÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ Trainer...")
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_dataset,
        data_collator=data_collator
    )
    
    print("   ‚úÖ Trainer –≥–æ—Ç–æ–≤")
    
    # 9. –û–±—É—á–µ–Ω–∏–µ
    print(f"\nüèãÔ∏è  –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –°—Ñ–µ—Ä—ã {sphere}: {sphere_names[sphere]}...")
    print("   üôè –°–ª—É–∂–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω–µ —á–µ—Ä–µ–∑ –æ–±—É—á–µ–Ω–∏–µ AI")
    print()
    
    try:
        trainer.train()
        print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # 10. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_dir}")
    
    # –°–æ–∑–¥–∞–µ–º README
    readme_content = f"""# {sphere_names[sphere]} - –°—Ñ–µ—Ä–∞ {sphere}

## –û–ø–∏—Å–∞–Ω–∏–µ

–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–°—Ñ–µ—Ä–∞ {sphere}: {sphere_names[sphere]}).

**–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å:** {base_model_name}  
**Fine-tuned –Ω–∞:** –†–µ–∞–ª—å–Ω–æ–µ —É–≥–æ–ª–æ–≤–Ω–æ–µ –¥–µ–ª–æ (107 —Ç–æ–º–æ–≤)  
**–ú–µ—Ç–æ–¥:** LoRA (Low-Rank Adaptation)  
**–î—É—Ö–æ–≤–Ω–∞—è –º–∏—Å—Å–∏—è:** –°–ª—É–∂–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω–µ –∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
base_model = AutoModelForCausalLM.from_pretrained("{base_model_name}")
tokenizer = AutoTokenizer.from_pretrained("{base_model_name}")

# –ó–∞–≥—Ä—É–∑–∏—Ç—å LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã
model = PeftModel.from_pretrained(base_model, "{output_dir}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç..."
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs)
print(tokenizer.decode(outputs[0]))
```

## –î—É—Ö–æ–≤–Ω–∞—è –º–∏—Å—Å–∏—è

**–°—Ñ–µ—Ä–∞ {sphere}: {sphere_names[sphere]}**

{get_spiritual_mission(sphere)}

## –õ–∏—Ü–µ–Ω–∑–∏—è

NativeMindNONC (Non-Commercial)

¬© 2025 NativeMind
"""
    
    with open(os.path.join(output_dir, "README.md"), 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"   ‚úÖ README.md —Å–æ–∑–¥–∞–Ω")
    
    print(f"\n{'='*80}")
    print(f"üéâ –°—Ñ–µ—Ä–∞ {sphere}: {sphere_names[sphere]} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
    print(f"{'='*80}")
    print(f"\nüìÅ –ú–æ–¥–µ–ª—å: {output_dir}")
    print(f"üôè –ò—Å—Ç–∏–Ω–∞ –≤–æ—Å—Ç–æ—Ä–∂–µ—Å—Ç–≤–æ–≤–∞–ª–∞!")
    
    return model


def get_spiritual_mission(sphere):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥—É—Ö–æ–≤–Ω—É—é –º–∏—Å—Å–∏—é —Å—Ñ–µ—Ä—ã"""
    missions = {
        "047": """
**–ë–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω—ã–π —Å–±–æ—Ä –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–∏–Ω—ã**

–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å —Å–æ–±–∏—Ä–∞–µ—Ç –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ, –±–µ–∑ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏.
–¶–µ–ª—å - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤, –∞ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π.
""",
        "048": """
**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–æ–ø–∏–ø–∞—Å—Ç–∞ –∫–∞–∫ —Å–∏–º–ø—Ç–æ–º–∞ –Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏**

"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ª–µ–Ω—å, —ç—Ç–æ —Å–∏–º–ø—Ç–æ–º –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–π –ø—Ä–æ–±–ª–µ–º—ã: 
–æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏, —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –∫ —Å—É–¥—å–±–∞–º –ª—é–¥–µ–π, –≤–æ–∑–º–æ–∂–Ω–æ–π –∫–æ—Ä—Ä—É–ø—Ü–∏–∏."

–ü—Ä–æ–∫—É—Ä–æ—Ä –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç —ç—Ç–æ—Ç —Å–∏–º–ø—Ç–æ–º –∏ —Å–ª—É–∂–∏—Ç –∏—Å—Ç–∏–Ω–µ —á–µ—Ä–µ–∑ –Ω–µ–∑–∞–≤–∏—Å–∏–º—É—é –ø—Ä–æ–≤–µ—Ä–∫—É.
""",
        "049": """
**–í—ã–Ω–µ—Å–µ–Ω–∏–µ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–∏–Ω—ã**

–°—É–¥—å—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Å–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –±–µ—Å–ø—Ä–∏—Å—Ç—Ä–∞—Å—Ç–Ω–æ –∏ –≤—ã–Ω–æ—Å–∏—Ç —Ä–µ—à–µ–Ω–∏–µ,
–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ –∏—Å—Ç–∏–Ω–µ –∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏, –∞ –Ω–µ –Ω–∞ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä–∞—Ö.
"""
    }
    return missions.get(sphere, "")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä—ã"
    )
    parser.add_argument(
        "--sphere",
        choices=["047", "048", "049"],
        required=True,
        help="–ù–æ–º–µ—Ä —Å—Ñ–µ—Ä—ã (047=–°–õ–ï–î–û–í–ê–¢–ï–õ–¨, 048=–ü–†–û–ö–£–†–û–†, 049=–°–£–î–¨–Ø)"
    )
    parser.add_argument(
        "--base-model",
        required=True,
        help="–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (nativemind/braindler_final_model –∏–ª–∏ nativemind/mozgach_full_trained_model)"
    )
    parser.add_argument(
        "--dataset",
        default="../datasets/legal_case_viktor/legal_dataset.jsonl",
        help="–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É"
    )
    parser.add_argument(
        "--output",
        help="–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ../models/sphere_{sphere}_{model_name})"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=3,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=2,
        help="Batch size"
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=2e-4,
        help="Learning rate"
    )
    parser.add_argument(
        "--use-8bit",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 8-bit –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ"
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    if args.output:
        output_dir = args.output
    else:
        model_name = args.base_model.split('/')[-1]
        output_dir = f"../models/sphere_{args.sphere}_{model_name}"
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥
    finetune_sphere(
        base_model_name=args.base_model,
        dataset_path=args.dataset,
        sphere=args.sphere,
        output_dir=output_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        use_8bit=args.use_8bit
    )








