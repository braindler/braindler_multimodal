#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å—Ñ–µ—Ä —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (073-078)

–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞

¬© 2025 NativeMind - NativeMindNONC License
"""

import os
import sys
import torch
import argparse
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import json
import time

def test_sphere_model_improved(sphere, model_path, test_prompts):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π —Å—Ñ–µ—Ä—ã —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    
    Args:
        sphere: –ù–æ–º–µ—Ä —Å—Ñ–µ—Ä—ã
        model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        test_prompts: –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    """
    
    sphere_names = {
        "073": "DEVELOPER",
        "074": "CODE_REVIEWER", 
        "075": "ARCHITECT",
        "076": "DEVOPS",
        "077": "QA_TESTER",
        "078": "TECH_WRITER"
    }
    
    print(f"\n{'='*80}")
    print(f"üß™ –†–ê–°–®–ò–†–ï–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–§–ï–†–´ {sphere}: {sphere_names[sphere]}")
    print(f"{'='*80}")
    
    if not os.path.exists(model_path):
        print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        return {"success": False, "metrics": {}}
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        print("   ‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        base_model = AutoModelForCausalLM.from_pretrained(
            "nativemind/shridhar_8k_multimodal",
            torch_dtype=torch.float32,
            device_map=None
        )
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞...")
        model = PeftModel.from_pretrained(base_model, model_path)
        print("   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(test_prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤...")
        
        results = []
        total_time = 0
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\n--- –¢–µ—Å—Ç {i} ---")
            print(f"–ü—Ä–æ–º–ø—Ç: {prompt}")
            
            start_time = time.time()
            
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = tokenizer(prompt, return_tensors="pt")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_new_tokens=300,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 200 –¥–æ 300
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id,
                    eos_token_id=tokenizer.eos_token_id,
                    repetition_penalty=1.1  # –î–æ–±–∞–≤–ª–µ–Ω penalty –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
                )
            
            generation_time = time.time() - start_time
            total_time += generation_time
            
            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response[len(prompt):].strip()
            
            print(f"–û—Ç–≤–µ—Ç: {response[:200]}{'...' if len(response) > 200 else ''}")
            print(f"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f}s")
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞
            quality_score = analyze_response_quality(prompt, response, sphere)
            print(f"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_score}/10")
            
            results.append({
                "prompt": prompt,
                "response": response,
                "generation_time": generation_time,
                "quality_score": quality_score
            })
            
            print("-" * 50)
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        avg_quality = sum(r["quality_score"] for r in results) / len(results)
        avg_time = total_time / len(results)
        
        metrics = {
            "avg_quality": avg_quality,
            "avg_generation_time": avg_time,
            "total_tests": len(results),
            "successful_tests": len([r for r in results if r["quality_score"] >= 6])
        }
        
        print(f"\nüìä –ú–ï–¢–†–ò–ö–ò –°–§–ï–†–´ {sphere}:")
        print(f"   üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f}/10")
        print(f"   ‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {avg_time:.2f}s")
        print(f"   ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {metrics['successful_tests']}/{metrics['total_tests']}")
        
        print(f"\n‚úÖ –°—Ñ–µ—Ä–∞ {sphere} ({sphere_names[sphere]}) –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        return {"success": True, "metrics": metrics, "results": results}
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ñ–µ—Ä—ã {sphere}: {e}")
        return {"success": False, "metrics": {}, "error": str(e)}

def analyze_response_quality(prompt, response, sphere):
    """
    –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ —Å—Ñ–µ—Ä—ã
    """
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    relevance_score = 0
    technical_accuracy = 0
    completeness = 0
    clarity = 0
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    if len(response) > 50:  # –ù–µ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
        relevance_score += 3
    if any(keyword in response.lower() for keyword in ["–∫–æ–¥", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π"]):
        relevance_score += 2
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
    if any(keyword in response.lower() for keyword in ["python", "javascript", "java", "—Ñ—É–Ω–∫—Ü–∏—è", "–∫–ª–∞—Å—Å", "–º–µ—Ç–æ–¥"]):
        technical_accuracy += 2
    if "```" in response or "–∫–æ–¥" in response.lower():
        technical_accuracy += 2
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã
    if len(response) > 100:
        completeness += 2
    if len(response) > 300:
        completeness += 1
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —è—Å–Ω–æ—Å—Ç–∏
    if len(response.split()) > 10:  # –ù–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        clarity += 2
    if not response.endswith("..."):  # –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        clarity += 1
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã
    sphere_bonus = 0
    if sphere == "073" and any(word in response.lower() for word in ["def ", "class ", "import ", "return"]):
        sphere_bonus += 2
    elif sphere == "074" and any(word in response.lower() for word in ["–æ—à–∏–±–∫–∞", "–ø—Ä–æ–±–ª–µ–º–∞", "—É–ª—É—á—à–µ–Ω–∏–µ", "—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥"]):
        sphere_bonus += 2
    elif sphere == "075" and any(word in response.lower() for word in ["–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "—Å–∏—Å—Ç–µ–º–∞", "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã", "–ø–∞—Ç—Ç–µ—Ä–Ω"]):
        sphere_bonus += 2
    elif sphere == "076" and any(word in response.lower() for word in ["docker", "kubernetes", "ci/cd", "devops"]):
        sphere_bonus += 2
    elif sphere == "077" and any(word in response.lower() for word in ["—Ç–µ—Å—Ç", "–ø—Ä–æ–≤–µ—Ä–∫–∞", "qa", "–±–∞–≥"]):
        sphere_bonus += 2
    elif sphere == "078" and any(word in response.lower() for word in ["–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "readme", "api", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ"]):
        sphere_bonus += 2
    
    total_score = min(10, relevance_score + technical_accuracy + completeness + clarity + sphere_bonus)
    return total_score

def main():
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å—Ñ–µ—Ä —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏")
    parser.add_argument("--models-dir", default="../models_improved",
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
    
    args = parser.parse_args()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ñ–µ—Ä—ã
    test_prompts = {
        "073": [
            "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞",
            "–°–æ–∑–¥–∞–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö",
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ –∫–æ–¥–∞",
            "–†–µ–∞–ª–∏–∑—É–π –ø–∞—Ç—Ç–µ—Ä–Ω Singleton –Ω–∞ Python",
            "–°–æ–∑–¥–∞–π REST API —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Flask"
        ],
        "074": [
            "–ü—Ä–æ–≤–µ—Ä—å —ç—Ç–æ—Ç –∫–æ–¥ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫",
            "–ù–∞–π–¥–∏ –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —ç—Ç–æ–º –∫–æ–¥–µ",
            "–ü—Ä–æ–≤–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è",
            "–í—ã—è–≤–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
            "–ü—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
        ],
        "075": [
            "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤",
            "–°–æ–∑–¥–∞–π –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é —Å–∏—Å—Ç–µ–º—É –¥–ª—è 1M –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
            "–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π —Å–∏—Å—Ç–µ–º—É —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏",
            "–í—ã–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞",
            "–°–æ–∑–¥–∞–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"
        ],
        "076": [
            "–ù–∞—Å—Ç—Ä–æ–π CI/CD pipeline –¥–ª—è Python –ø—Ä–æ–µ–∫—Ç–∞",
            "–°–æ–∑–¥–∞–π Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è",
            "–ù–∞—Å—Ç—Ä–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ Kubernetes",
            "–ù–∞—Å—Ç—Ä–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"
        ],
        "077": [
            "–ù–∞–ø–∏—à–∏ unit —Ç–µ—Å—Ç—ã –¥–ª—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏",
            "–°–æ–∑–¥–∞–π –ø–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è API",
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ UI",
            "–ü—Ä–æ–≤–µ—Ä—å –ø–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–¥–∞ —Ç–µ—Å—Ç–∞–º–∏",
            "–°–æ–∑–¥–∞–π —Ç–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
        ],
        "078": [
            "–ù–∞–ø–∏—à–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è API",
            "–°–æ–∑–¥–∞–π README –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞",
            "–ù–∞–ø–∏—à–∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
            "–°–æ–∑–¥–∞–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é",
            "–ù–∞–ø–∏—à–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é"
        ]
    }
    
    print("==================================================================================")
    print("üß™ –†–ê–°–®–ò–†–ï–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–´–• –°–§–ï–† –†–ê–ó–†–ê–ë–û–¢–ö–ò")
    print("==================================================================================")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
    available_spheres = []
    
    for sphere in ["073", "074", "075", "076", "077", "078"]:
        model_path = f"{args.models_dir}/sphere_{sphere}_improved"
        if os.path.exists(model_path):
            available_spheres.append(sphere)
            print(f"‚úÖ –°—Ñ–µ—Ä–∞ {sphere}: {model_path}")
        else:
            print(f"‚ùå –°—Ñ–µ—Ä–∞ {sphere}: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(available_spheres)} —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å—Ñ–µ—Ä")
    
    if not available_spheres:
        print("\n‚ùå –ù–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!")
        return
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π —Å—Ñ–µ—Ä—ã
    results = {}
    overall_metrics = {
        "total_quality": 0,
        "total_tests": 0,
        "successful_tests": 0
    }
    
    for sphere in available_spheres:
        model_path = f"{args.models_dir}/sphere_{sphere}_improved"
        
        result = test_sphere_model_improved(
            sphere, 
            model_path, 
            test_prompts[sphere]
        )
        results[sphere] = result
        
        if result["success"]:
            metrics = result["metrics"]
            overall_metrics["total_quality"] += metrics["avg_quality"]
            overall_metrics["total_tests"] += metrics["total_tests"]
            overall_metrics["successful_tests"] += metrics["successful_tests"]
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "="*80)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –£–õ–£–ß–®–ï–ù–ù–´–• –ú–û–î–ï–õ–ï–ô")
    print("="*80)
    
    successful = sum(1 for result in results.values() if result["success"])
    total = len(results)
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {successful}/{total}")
    
    if overall_metrics["total_tests"] > 0:
        avg_quality = overall_metrics["total_quality"] / len([r for r in results.values() if r["success"]])
        success_rate = overall_metrics["successful_tests"] / overall_metrics["total_tests"] * 100
        
        print(f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f}/10")
        print(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {success_rate:.1f}%")
    
    print()
    
    for sphere, result in results.items():
        if result["success"]:
            metrics = result["metrics"]
            status = f"‚úÖ –£–°–ü–ï–®–ù–û ({metrics['avg_quality']:.1f}/10)"
        else:
            status = "‚ùå –û–®–ò–ë–ö–ê"
        print(f"–°—Ñ–µ—Ä–∞ {sphere}: {status}")
    
    print(f"\nüôè –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()
