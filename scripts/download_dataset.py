#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ kene_multimodal_gift

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π Braindler & Mozgach

¬© 2025 NativeMind - NativeMindNONC License
"""

import os
import sys
from pathlib import Path
from datasets import load_dataset


def download_kene_multimodal_gift(
    output_dir: str = "./datasets/kene_multimodal_gift",
    split: str = "train"
):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç kene_multimodal_gift
    
    Args:
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        split: –ö–∞–∫–æ–π split –∑–∞–≥—Ä—É–∂–∞—Ç—å (train/test/validation)
    """
    print("=" * 80)
    print("üéÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ kene_multimodal_gift")
    print("=" * 80)
    print()
    print("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
    print("   - –†–∞–∑–º–µ—Ä: ~1 GB")
    print("   - –§–∞–π–ª–æ–≤: 50+")
    print("   - –ú–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ê—É–¥–∏–æ, –í–∏–¥–µ–æ")
    print()
    print("üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
    print("   üéµ –î—É—Ö–æ–≤–Ω–∞—è –º—É–∑—ã–∫–∞ (–ò–ö–ê–†–û–°, –î–∂–∏–≤ –î–∂–∞–≥–æ)")
    print("   üß∏ –î–µ—Ç—Å–∫–∏–µ –∏–≥—Ä—É—à–∫–∏")
    print("   üé® –î–µ—Ç—Å–∫–∏–µ —Ä–∏—Å—É–Ω–∫–∏")
    print("   üå¥ –§–æ—Ç–æ –ø—Ä–∏—Ä–æ–¥—ã (–¢–∞–∏–ª–∞–Ω–¥)")
    print("   üé¨ –í–∏–¥–µ–æ –∫–æ–Ω—Ç–µ–Ω—Ç")
    print()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ HuggingFace: nativemind/kene_multimodal_gift")
        print(f"   Split: {split}")
        print()
        
        dataset = load_dataset(
            "nativemind/kene_multimodal_gift",
            split=split,
            cache_dir=output_dir
        )
        
        print(f"\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        print(f"   –ü—Ä–∏–º–µ—Ä–æ–≤: {len(dataset)}")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print("\nüìù –ü—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
        for i, example in enumerate(dataset.select(range(min(3, len(dataset))))):
            print(f"\n   –ü—Ä–∏–º–µ—Ä {i+1}:")
            for key, value in example.items():
                if isinstance(value, (str, int, float, bool)):
                    print(f"      {key}: {value}")
                else:
                    print(f"      {key}: <{type(value).__name__}>")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        info_path = os.path.join(output_dir, "dataset_info.txt")
        with open(info_path, 'w', encoding='utf-8') as f:
            f.write("Kene Multimodal Gift Dataset\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"–†–∞–∑–º–µ—Ä: {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤\n")
            f.write(f"Split: {split}\n")
            f.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω: {os.path.dirname(os.path.abspath(__file__))}\n")
            f.write("\n–ò—Å—Ç–æ—á–Ω–∏–∫: https://huggingface.co/datasets/nativemind/kene_multimodal_gift\n")
        
        print(f"   üíæ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {info_path}")
        
        return dataset
    
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
        print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
        print("   2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ datasets: pip install datasets")
        print("   3. –í–æ–π–¥–∏—Ç–µ –≤ HuggingFace: huggingface-cli login")
        sys.exit(1)


def download_all_datasets():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã"""
    print("\nüéÅ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤")
    print()
    
    datasets = [
        ("kene_multimodal_gift", "./datasets/kene_multimodal_gift"),
    ]
    
    for name, output_dir in datasets:
        print(f"\n{'='*80}")
        print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞: {name}")
        print(f"{'='*80}\n")
        
        try:
            download_kene_multimodal_gift(output_dir)
        except Exception as e:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {name}: {e}")
            continue
    
    print("\n" + "="*80)
    print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("="*80)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–ó–∞–≥—Ä—É–∑–∫–∞ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ kene_multimodal_gift"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./datasets/kene_multimodal_gift",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"
    )
    parser.add_argument(
        "--split",
        type=str,
        default="train",
        choices=["train", "test", "validation"],
        help="–ö–∞–∫–æ–π split –∑–∞–≥—Ä—É–∂–∞—Ç—å"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã"
    )
    
    args = parser.parse_args()
    
    if args.all:
        download_all_datasets()
    else:
        download_kene_multimodal_gift(args.output_dir, args.split)

